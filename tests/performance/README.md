# Performance Testing Module

Module Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t há»‡ thá»‘ng Smart Itinerary Planner (Recommendation + Scheduling).

## ğŸ“ Cáº¥u trÃºc

```
tests/performance/
â”œâ”€â”€ __init__.py                      # Package init
â”œâ”€â”€ benchmark_speed.py               # Äo tá»‘c Ä‘á»™ tá»«ng bÆ°á»›c cá»§a pipeline
â”œâ”€â”€ evaluate_recommendation.py       # ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c recommendation
â”œâ”€â”€ run_performance_tests.py         # Script cháº¡y táº¥t cáº£ tests
â””â”€â”€ reports/                         # Folder chá»©a káº¿t quáº£
    â”œâ”€â”€ speed_benchmark_*.json
    â”œâ”€â”€ evaluation_*.json
    â””â”€â”€ performance_summary_*.json
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Cháº¡y táº¥t cáº£ tests

```bash
cd tests/performance
python run_performance_tests.py
```

### 2. Cháº¡y tá»«ng test riÃªng láº»

**Speed Benchmark:**
```bash
python benchmark_speed.py
```

**Recommendation Evaluation:**
```bash
python evaluate_recommendation.py
```

## ğŸ“Š CÃ¡c metrics Ä‘Æ°á»£c Ä‘o

### A. Speed Benchmark

Äo thá»i gian tá»«ng bÆ°á»›c cá»§a pipeline:

1. **Load Places** - Táº£i dá»¯ liá»‡u tá»« MongoDB
2. **BERT Embeddings** - Precompute semantic embeddings
3. **Hybrid Scoring** - TÃ­nh Ä‘iá»ƒm BERT + SVD
4. **Graph Building** - XÃ¢y dá»±ng Ä‘á»“ thá»‹ & Dijkstra preprocessing
5. **Scheduling** - Sáº¯p xáº¿p lá»‹ch trÃ¬nh (Greedy Block Scheduling)
6. **Route Optimization** - Tá»‘i Æ°u transport mode

**Output:**
- Thá»i gian tá»«ng bÆ°á»›c (seconds)
- Tá»· lá»‡ pháº§n trÄƒm cá»§a má»—i bÆ°á»›c
- Tá»•ng thá»i gian recommendation (khÃ´ng tÃ­nh I/O)
- Throughput (places/second)
- Scalability test vá»›i 50, 100, 200 places

### B. Recommendation Quality Evaluation

ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c báº±ng binary classification metrics:

**Ground Truth:** Places mÃ  users Ä‘Ã£ tá»«ng chá»n trong tour history

**Predictions:** Top-K recommendations tá»« há»‡ thá»‘ng

**Metrics:**
- **TP** (True Positives): Recommend Ä‘Ãºng (user thÃ­ch)
- **FP** (False Positives): Recommend sai (user khÃ´ng thÃ­ch)
- **FN** (False Negatives): Bá» sÃ³t (user thÃ­ch nhÆ°ng khÃ´ng recommend)
- **TN** (True Negatives): ÄÃºng khÃ´ng recommend
- **POD** (Probability of Detection) = Recall = TP/(TP+FN)
- **Precision** = TP/(TP+FP)
- **F1-Score** = 2 * (Precision * Recall) / (Precision + Recall)
- **FAR** (False Alarm Rate) = FP/(FP+TN)

## ğŸ“‹ YÃªu cáº§u

- MongoDB Ä‘ang cháº¡y vá»›i data Ä‘Ã£ import
- Collections cáº§n thiáº¿t:
  - `places` - Danh sÃ¡ch Ä‘á»‹a Ä‘iá»ƒm
  - `tours` - Tour history (Ä‘á»ƒ lÃ m ground truth)
- Virtual environment Ä‘Ã£ Ä‘Æ°á»£c activate

## ğŸ“ˆ Káº¿t quáº£ máº«u

### Speed Benchmark
```
1_load_places                : 0.234s (5.2%)
2_bert_embeddings            : 1.456s (32.1%)
3_hybrid_scoring             : 0.892s (19.7%)
4_graph_building             : 1.123s (24.8%)
5_scheduling                 : 0.567s (12.5%)
6_route_optimization         : 0.256s (5.7%)
--------------------------------------------
TOTAL RECOMMENDATION TIME    : 4.528s
```

### Recommendation Evaluation
```
TP: 8.2    FP: 11.8    FN: 6.3    TN: 173.7

POD (Recall)    : 0.565 (56.5%)
Precision       : 0.410 (41.0%)
F1-Score        : 0.476
FAR             : 0.064 (6.4%)
```

## ğŸ¯ Giáº£i thÃ­ch Metrics

- **POD cao** = Há»‡ thá»‘ng recommend Ä‘Æ°á»£c nhiá»u places user thÃ­ch
- **Precision cao** = Há»‡ thá»‘ng Ã­t recommend nháº§m places user khÃ´ng thÃ­ch
- **F1 cao** = CÃ¢n báº±ng tá»‘t giá»¯a POD vÃ  Precision
- **FAR tháº¥p** = Tá»· lá»‡ false alarm tháº¥p (tá»‘t)

## ğŸ”§ TÃ¹y chá»‰nh

Trong `run_performance_tests.py`, cÃ³ thá»ƒ thay Ä‘á»•i:

```python
# Thay Ä‘á»•i thÃ nh phá»‘ test
run_all_performance_tests(city="Ha Noi")

# Trong benchmark_speed.py
benchmark.benchmark_full_pipeline(
    city="Ho Chi Minh City",
    num_days=5,           # Sá»‘ ngÃ y
    max_places=500        # Sá»‘ places
)

# Trong evaluate_recommendation.py
evaluator.evaluate_with_tour_history(
    city="Ho Chi Minh City",
    k_recommendations=30  # Top-K
)
```
